{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ9xve4txP3WYSg0mCeLBr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n","os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"],"metadata":{"id":"qSXe3bWKEjfq","executionInfo":{"status":"ok","timestamp":1748908894614,"user_tz":240,"elapsed":359,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Google\n","\n","Official Docs: https://ai.google.dev/gemini-api/docs/text-generation"],"metadata":{"id":"90gyFCDzGD0v"}},{"cell_type":"markdown","source":["### Simple Request"],"metadata":{"id":"mC77rxvqGMSX"}},{"cell_type":"code","source":["from google import genai\n","\n","client = genai.Client(api_key=os.environ['GOOGLE_API_KEY'])\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",")\n","print(response.text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijuWjo75E77F","executionInfo":{"status":"ok","timestamp":1748908944976,"user_tz":240,"elapsed":2166,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"7d651613-b1c5-428a-9d80-ece584d83d3e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["AI learns patterns from data to make predictions or decisions.\n","\n"]}]},{"cell_type":"markdown","source":["### Streaming"],"metadata":{"id":"_mW2ZL1WGO1c"}},{"cell_type":"code","source":["response = client.models.generate_content_stream(\n","    model=\"gemini-2.0-flash\",\n","    contents=[\"Explain how AI works\"]\n",")\n","for chunk in response:\n","    print(chunk.text, end=\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LzwUSnXUGOZh","executionInfo":{"status":"ok","timestamp":1748909006178,"user_tz":240,"elapsed":11057,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"4e2e087d-e9e1-4957-f884-2b7044dc919a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Okay, let's break down how AI works, aiming for clarity and avoiding overly technical jargon where possible.  It's a broad field, so we'll focus on the core concepts.\n","\n","**At its Heart:  Mimicking Intelligence**\n","\n","AI (Artificial Intelligence) is essentially about creating computer systems that can perform tasks that typically require human intelligence.  This includes things like:\n","\n","*   **Learning:**  Improving performance over time based on data.\n","*   **Problem-solving:**  Finding solutions to complex issues.\n","*   **Decision-making:**  Choosing the best course of action.\n","*   **Understanding language:**  Processing and interpreting human languages.\n","*   **Perception:**  Interpreting sensory input (like images or sound).\n","\n","**Key Approaches to Achieving AI:**\n","\n","There are several different approaches to building AI systems, but the following are the most prominent:\n","\n","1.  **Machine Learning (ML): The Data-Driven Approach**\n","\n","    *   **Core Idea:** Instead of explicitly programming a computer to do something, you feed it a lot of data and let it learn patterns and relationships from that data.  The more data, the better it can learn.\n","    *   **How it Works:**\n","        *   **Data Collection:** Gathering a relevant dataset.  For example, if you want to build an AI that recognizes cats in pictures, you'd need a massive dataset of images labeled \"cat\" and \"not cat.\"\n","        *   **Algorithm Selection:** Choosing an appropriate machine learning algorithm.  Different algorithms are suited for different types of problems.  Common examples include:\n","            *   **Supervised Learning:** The algorithm is trained on labeled data (input and desired output are provided).  Examples:\n","                *   **Classification:** Categorizing data (e.g., spam/not spam). Algorithms like Support Vector Machines (SVMs), Decision Trees, and Random Forests are used.\n","                *   **Regression:** Predicting a continuous value (e.g., predicting house prices).  Linear Regression and Polynomial Regression are common.\n","            *   **Unsupervised Learning:** The algorithm is given unlabeled data and must find patterns on its own.  Examples:\n","                *   **Clustering:** Grouping similar data points together (e.g., customer segmentation).  K-Means is a popular algorithm.\n","                *   **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., for data visualization).  Principal Component Analysis (PCA) is an example.\n","            *   **Reinforcement Learning:** The algorithm learns by trial and error, receiving rewards or penalties for its actions in an environment.  (e.g., training a robot to walk).  Q-learning and Deep Q-Networks (DQN) are used.\n","        *   **Training:**  The algorithm analyzes the data and adjusts its internal parameters to improve its performance.  This often involves an iterative process of making predictions, evaluating the accuracy of those predictions, and adjusting the parameters to reduce errors.\n","        *   **Testing/Validation:**  After training, the algorithm is tested on a separate dataset to evaluate its generalization ability (how well it performs on unseen data).\n","        *   **Deployment:**  The trained model is deployed to make predictions on new data.\n","\n","    *   **Analogy:** Think of teaching a child to recognize apples. You show them many pictures of apples, pointing out their characteristics (round, red, etc.).  The child learns to associate these characteristics with the label \"apple.\" Machine learning does something similar, but with mathematical equations and algorithms.\n","\n","2.  **Deep Learning (DL): A Powerful Subset of Machine Learning**\n","\n","    *   **Core Idea:** Uses artificial neural networks with many layers (hence \"deep\") to learn complex patterns from data.  It's particularly effective for tasks like image recognition, natural language processing, and speech recognition.\n","    *   **How it Works:**\n","        *   **Neural Networks:**  Inspired by the structure of the human brain, neural networks consist of interconnected nodes (neurons) organized in layers.\n","        *   **Layers:**  Each layer transforms the input data in some way.  Early layers might detect simple features (e.g., edges in an image), while later layers combine these features to recognize more complex patterns (e.g., faces).\n","        *   **Training (Backpropagation):**  The network learns by adjusting the connections between neurons (weights) based on the errors in its predictions. This process is called backpropagation.\n","        *   **Large Datasets:**  Deep learning requires very large datasets to train effectively.  The more data, the better the network can learn complex relationships.\n","    *   **Examples:**\n","        *   **Convolutional Neural Networks (CNNs):**  Used for image and video processing.\n","        *   **Recurrent Neural Networks (RNNs):**  Used for sequential data like text and speech.\n","        *   **Transformers:** A more recent architecture revolutionizing NLP, powering models like BERT and GPT.\n","\n","    *   **Analogy:** Imagine trying to teach a computer to recognize different breeds of dogs. With a simple machine learning model, you might manually define features like ear shape, tail length, and fur color. Deep learning, on the other hand, can automatically learn these features from the raw pixel data of the images, often identifying more subtle and complex characteristics that humans might miss.\n","\n","3.  **Rule-Based Systems (Expert Systems): The Knowledge-Driven Approach**\n","\n","    *   **Core Idea:** Relies on a set of predefined rules and knowledge to make decisions.\n","    *   **How it Works:**\n","        *   **Knowledge Base:** Contains facts and rules about a specific domain.\n","        *   **Inference Engine:** Uses the rules to reason about the facts and draw conclusions.\n","        *   **User Interface:** Allows users to interact with the system.\n","    *   **Example:** A medical diagnosis system might use rules like \"IF patient has fever AND cough AND sore throat THEN suspect influenza.\"\n","    *   **Limitations:**  Difficult to scale to complex problems, as the rules need to be manually defined and updated. They also struggle with uncertainty and incomplete information.\n","\n","4.  **Symbolic AI:**\n","\n","    *  **Core Idea:** Focuses on representing knowledge using symbols and logical rules.\n","    *  **How it Works:**\n","        * Involves creating explicit representations of knowledge, such as using formal logic or semantic networks.\n","        * Uses algorithms to reason and manipulate these symbols to solve problems.\n","    *  **Example:** Early natural language processing systems that relied on parsing sentences into symbolic representations to understand their meaning.\n","    *  **Limitations:** Can struggle with tasks that require intuition or common sense, as these are difficult to represent symbolically.\n","\n","**Important Considerations:**\n","\n","*   **Data Quality:** The quality of the data is crucial for the performance of machine learning models.  Garbage in, garbage out.\n","*   **Bias:**  AI models can inherit biases from the data they are trained on, leading to unfair or discriminatory outcomes.  It's important to be aware of potential biases and mitigate them.\n","*   **Explainability:**  Some AI models (especially deep learning models) can be difficult to interpret, making it hard to understand why they make certain decisions.  This can be a problem in sensitive applications where transparency is important.\n","*   **Computational Resources:** Training complex AI models can require significant computational resources, including powerful hardware and large amounts of data.\n","\n","**Levels of AI:**\n","\n","*   **Narrow or Weak AI:** Designed for a specific task (e.g., spam filtering, recommendation systems).  Most AI systems today fall into this category.\n","*   **General or Strong AI:** Possesses human-level intelligence and can perform any intellectual task that a human being can.  This is still largely theoretical.\n","*   **Super AI:** Surpasses human intelligence in all aspects.  Also theoretical and raises ethical concerns.\n","\n","**In Summary:**\n","\n","AI is a broad field encompassing various techniques for creating intelligent systems. Machine learning, especially deep learning, is currently the dominant approach, relying on data and algorithms to learn patterns and make predictions. Rule-based systems offer an alternative approach based on explicit knowledge and reasoning.  The future of AI will likely involve combining these different approaches and addressing the ethical and societal implications of increasingly powerful AI systems.\n"]}]},{"cell_type":"markdown","source":["## OpenAI\n","\n","Official Docs: https://platform.openai.com/docs/guides/text"],"metadata":{"id":"IbJ8RqdEIC7U"}},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n","\n","response = client.responses.create(\n","    model=\"gpt-4.1-nano\",\n","    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",")\n","\n","print(response.output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rjXlPByGObj","executionInfo":{"status":"ok","timestamp":1748909438478,"user_tz":240,"elapsed":3836,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"b256c3f5-ae30-4bbb-b170-160d490de654"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, a gentle unicorn with shimmering hooves and a starry mane wandered into a magical forest, where it found a cozy spot to dream beneath the moonlit sky.\n"]}]},{"cell_type":"markdown","source":["### Message roles and instruction following"],"metadata":{"id":"nvg8SlhdINB_"}},{"cell_type":"code","source":["response = client.responses.create(\n","    model=\"gpt-4.1-nano\",\n","    instructions=\"Talk like a pirate.\",\n","    input=\"Are semicolons optional in JavaScript?\",\n",")\n","\n","print(response.output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0c8kQoKoGOdv","executionInfo":{"status":"ok","timestamp":1748909489433,"user_tz":240,"elapsed":1340,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"ee63d269-9f7b-4b6b-ea11-2640ccdcd346"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Arrr, matey! In JavaScript, ye may find semicolons often the law of the land, but they be not always strictly required. The JavaScript engine be usin’ a set of rules called Automatic Semicolon Insertion (ASI). It tries to fill in the gaps where ye forget to put a semicolon, but beware, matey! It might not always fetch the results ye be plannin’. \n","\n","So, sometimes ye can sail without 'em, but it be safer to include yer semicolons to steer clear of treacherous bugs. Yarrr!\n"]}]},{"cell_type":"markdown","source":["## LangChain\n","\n","Official Docs: https://python.langchain.com/docs/how_to/chat_models_universal_init/"],"metadata":{"id":"Wk4LsQrXLLXB"}},{"cell_type":"code","source":["!pip install -qU langchain>=0.2.8 langchain-openai langchain-google-vertexai langchain-google-genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jn3HZjpdIm2J","executionInfo":{"status":"ok","timestamp":1748910598009,"user_tz":240,"elapsed":6626,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"3a4d7d31-624b-4e85-eb40-ddf5781a57ee"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from langchain.chat_models import init_chat_model"],"metadata":{"id":"FvHfeJVmL4LU","executionInfo":{"status":"ok","timestamp":1748910443511,"user_tz":240,"elapsed":979,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["gpt_4o = init_chat_model(\"gpt-4.1-nano\", model_provider=\"openai\", temperature=0)\n","\n","gpt_4o.invoke(\"Who are you?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0mD9g5_LtCw","executionInfo":{"status":"ok","timestamp":1748910445746,"user_tz":240,"elapsed":1563,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"816e3180-64b2-45dc-ea4d-1e9a7f12c9e1"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='I am an AI language model developed to assist you with information, answer questions, and engage in conversations. How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 11, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-Be9mx0D1cTGU6GsLYD9kJDTiHirql', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--83ee12ab-58a5-4de0-baac-957e5dd60d8a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 28, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["gemini_2 = init_chat_model(\n","    \"gemini-2.0-flash\", model_provider=\"google_genai\", temperature=0\n",")\n","\n","gemini_2.invoke(\"Who are you?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DJR1o5-LtE7","executionInfo":{"status":"ok","timestamp":1748910631481,"user_tz":240,"elapsed":400,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"000d50f3-c3e3-4ac4-ac11-76f5d2932740"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--edbea432-f837-4df7-aefb-18734fc002ad-0', usage_metadata={'input_tokens': 4, 'output_tokens': 12, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["chunks = []\n","for chunk in gemini_2.stream(\"what color is the sky?\"):\n","    chunks.append(chunk)\n","    print(chunk.content, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_L9kUX-BLtHP","executionInfo":{"status":"ok","timestamp":1748910828661,"user_tz":240,"elapsed":928,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"cf6fba1d-851e-4936-cd44-d43b8c482853"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["The sky is **blue** on a clear day.\n","\n","However, the color of the sky can change depending on various factors:\n","\n","*   **Sunrise/Sunset:** The sky can be orange, red, pink, or purple.\n","*   **Clouds:** The sky can be white, gray, or dark gray.\n","*   **Night:** The sky is black.\n","*   **Pollution/Dust:** The sky can appear hazy or yellowish.\n","\n","So, while the most common answer is blue, it's not always the case!\n"]}]},{"cell_type":"code","source":["chunks = []\n","for chunk in gpt_4o.stream(\"what color is the sky?\"):\n","    chunks.append(chunk)\n","    print(chunk.content, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tog8PUtoLtJY","executionInfo":{"status":"ok","timestamp":1748910843135,"user_tz":240,"elapsed":906,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"fbd86abc-4bca-45f7-ebb4-eefa13275196"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["The color of the sky is typically blue during the day due to the scattering of sunlight by Earth's atmosphere. However, it can appear in various colors such as red, orange, pink, or purple during sunrise and sunset, and it can be gray or overcast when the sky is cloudy."]}]},{"cell_type":"code","source":["gpt_4o = init_chat_model(\"gpt-4.1-nano\", model_provider=\"openai\", temperature=0)\n","\n","response = gpt_4o.invoke(\"Who are you?\")\n","print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-PoncOzP8oP","executionInfo":{"status":"ok","timestamp":1748911614168,"user_tz":240,"elapsed":643,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"a4270e2c-8d8c-4ae9-d79f-84c988abc112"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello! I am an AI language model developed to assist you with information, answer questions, and engage in conversations. How can I help you today?\n"]}]},{"cell_type":"markdown","source":["## Chatbot"],"metadata":{"id":"09BNDZmcPjBh"}},{"cell_type":"code","source":["while True:\n","    user_input = input(\"You: \")\n","    if str(user_input).lower() in [\"exit\", \"quit\", \"bye\"]:\n","        print(\"Goodbye!\")\n","        break\n","    response = gpt_4o.invoke(user_input)\n","    print(response.content)\n","    print(\"-\" * 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrnufjdvLtLz","executionInfo":{"status":"ok","timestamp":1748911963390,"user_tz":240,"elapsed":39614,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"e1b3ecad-b1cd-4f2a-eda3-a046f2416351"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["You: Hi, my name is John. Nice to meet you!\n","Hi John! Nice to meet you too. How can I assist you today?\n","------------------------------\n","You: What is my name?\n","I'm sorry, but I don't know your name.\n","------------------------------\n","You: bye\n","Goodbye!\n"]}]},{"cell_type":"markdown","source":["## Chatbot with chat history"],"metadata":{"id":"s3FEoKeKRvEm"}},{"cell_type":"code","source":["build_prompt = lambda context: f\"\"\"\n","You are a helpful AI assistant. Below is the conversation history between the user and the assistant:\n","{context}\n","\n","Please answer the user’s most recent question (the last message) as clearly and accurately as possible,\n","using information from the conversation history if needed.\n","\"\"\"\n","\n","chat_history = []\n","while True:\n","    user_input = input(\"You: \").strip().lower()\n","    chat_history.append({\"Human\": user_input})\n","    if user_input in [\"exit\", \"quit\", \"bye\"]:\n","        print(\"Goodbye!\")\n","        break\n","    response = gpt_4o.invoke(build_prompt(chat_history))\n","    chat_history.append({\"AI\": response})\n","    print(response.content)\n","    print(\"-\" * 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCCANLHjQwKJ","executionInfo":{"status":"ok","timestamp":1748912764650,"user_tz":240,"elapsed":35302,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"f992a459-353b-4911-ecf1-6da6c0477d10"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["You: Hi, my name is John. Nice to meet you!\n","Hello, John! Nice to meet you too. How can I assist you today?\n","------------------------------\n","You: What is my name?\n","Your name is John.\n","------------------------------\n","You: bye\n","Goodbye!\n"]}]},{"cell_type":"markdown","source":["## Gradio UI - Chatbot Interface\n","\n","Official Docs: https://www.gradio.app/guides/creating-a-chatbot-fast"],"metadata":{"id":"fW5m1WuAXXmV"}},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-p1bBMCyXUGw","executionInfo":{"status":"ok","timestamp":1748913468119,"user_tz":240,"elapsed":16639,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"24b2d7e4-2ecb-40fb-94de-64e9a26f51be"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.32.1-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.10.2 (from gradio)\n","  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.32.1-py3-none-any.whl (54.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.6.0 gradio-5.32.1 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.3\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","\n","def llm_respond(message, history):\n","    response = gpt_4o.invoke(message)\n","    return response.content\n","\n","gr.ChatInterface(\n","    fn=llm_respond,\n","    type=\"messages\"\n",").launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"iPLCiSHOXdOn","executionInfo":{"status":"ok","timestamp":1748913732633,"user_tz":240,"elapsed":1783,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"2f56d2ff-0963-4df7-8c43-9ec381d368e5"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://1c583686ddddb93e2f.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://1c583686ddddb93e2f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["build_prompt = lambda context, input: f\"\"\"\n","You are a helpful AI assistant. Below is the conversation history between the user and the assistant:\n","{context}\n","\n","Please answer the user’s question (the last message) as clearly and accurately as possible,\n","using information from the conversation history if needed. The question is: {input}\n","\"\"\"\n","\n","# chat_history = []\n","\n","def llm_respond_with_history(message, history):\n","    # print(f\"build_prompt: {build_prompt(history, message)}\")\n","    response = gpt_4o.invoke(build_prompt(history, message))\n","    return response.content\n","\n","gr.ChatInterface(\n","    fn=llm_respond_with_history,\n","    type=\"messages\"\n",").launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"GSARe-7cXdU3","executionInfo":{"status":"ok","timestamp":1748913800937,"user_tz":240,"elapsed":1437,"user":{"displayName":"Jiawei Liu","userId":"07456475938709546989"}},"outputId":"110d18ac-0be4-4c09-dc9c-9a8055cd1bd8"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://217279ae4a35983199.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://217279ae4a35983199.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":[],"metadata":{"id":"-LSZjKqNYsDr"},"execution_count":null,"outputs":[]}]}